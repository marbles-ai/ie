License: MIT's License ("to deal in the Software without restriction")

The code was written with Eclipse based on the existence of the .project .classpath files.
It uses Torch and Lua for training.
There are several example models available (too large for github; ask if you'd like me to e-mail you one.)

Parsing
-
The words in a sentence are first tagged by the supertagger, and then parsed by the A-star parser (Details below)


Training
-
Supertagged sentences are used for training in the format: word|pos|category in the file gold.stagged. (pos is not necessary)
Use C&C parser's generate program to extract testing/training data from CCGBank.

To train, run './do_training.sh <name of model> <directory containing embeddings> <training data> <development data>'

To evaluate, run: './do_experiments.sh <model directory> <directory to testing data> <name of model>'

-
Wordnet based Lemmatizer:

Lemmatize -> set word to lower case, get Synset Type, and return first stem. * How many stems could there be?*
    Only available synset types are: Noun, Verb, Adverb, Adjective. *Is this ok?*
    Stems are pulled from large exc files associating words with their stems. Examples:

    verb.exc
    abetted abet
    abetting abet
    abhorred abhor
    abhorring abhor

    noun.exc
    phalli phallus
    pharynges pharynx
    phenomena phenomenon
    phi-phenomena phi-phenomenon

    adverb.exc
    best well
    better well
    deeper deeply
    farther far

    adjective.exc
    bendier bendy
    bendiest bendy
    best good
    better good well
    bigger big

Syntax -> Use lemmatized words to derive meaning

    Tagger -> high level class that assigns a distribution of lexical categories over a list of words. It returns an ordered list of SyntaxTreeNodes that represent their likely category assignments.

    TagDict -> This loads a word:tag_set dictionary from the model directory, or writes into a model directory. It uses a HashMultiset to keep track of the set of tags applicable for a word.

    Category -> Assigns a type:feature to a string.

    Tagger Embeddings -> The Tagger Embedder is responsible for setting context; an embedding captures syntactic and semantic information.
        In this case, the contextwindow is set to 3; this means that a word considers its neighbors within 3 words before and after itself.
        Each of the word embeddings, suffixes (what does the word end with) and capitalization (is it capitalized?) are added to the Neural Network feature vector.

        * Some modern supertaggers use Character-level embedding -- this is important when considering word morphology! This is not the case for easyCCG* http://jmlr.org/proceedings/papers/v32/santos14.pdf (CharWNN)
            - Word-level embeddings: syntactic and semantic information
            - Char-level embeddings: morphological and shape information.
            - EasyCCG kinda cheats by just considering suffixes (it should also consider prefixes)

    SyntaxTreeNode -> A node in a tree that represents the relationships between the supertagged words in the sentence.

    ParserAStar -> Take a tagger, some input, categories, rules, combinator defs and pop out tagged results!
        parseAStar -> Take in supertagged inputs and return a set of valid parses



